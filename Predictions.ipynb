{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachit/Documents/Python shit/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import spectrogram\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Delegate.__del__ at 0x15a279d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rachit/Documents/Python shit/.venv/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py\", line 121, in __del__\n",
      "    if self._library is not None:\n",
      "AttributeError: 'Delegate' object has no attribute '_library'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU delegate not available: dlopen(libtensorflowlite_gpu_delegate.so, 0x0006): tried: 'libtensorflowlite_gpu_delegate.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtensorflowlite_gpu_delegate.so' (no such file), '/usr/lib/libtensorflowlite_gpu_delegate.so' (no such file, not in dyld cache), 'libtensorflowlite_gpu_delegate.so' (no such file)\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Load GPU Delegate --------------------\n",
    "delegate = None\n",
    "try:\n",
    "    import tflite_runtime.interpreter as tflite\n",
    "except ModuleNotFoundError:\n",
    "    from tensorflow import lite as tflite\n",
    "\n",
    "try:\n",
    "    delegate = tf.lite.experimental.load_delegate(\"libtensorflowlite_gpu_delegate.so\")\n",
    "    print(\"GPU delegate loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"GPU delegate not available:\", e)\n",
    "\n",
    "# -------------------- Patch Interpreter BEFORE importing wrapper --------------------\n",
    "if not hasattr(tflite, \"_original_interpreter\"):\n",
    "    tflite._original_interpreter = tflite.Interpreter\n",
    "\n",
    "    def Interpreter_with_delegate(*args, **kwargs):\n",
    "        if delegate is not None:\n",
    "            kwargs[\"experimental_delegates\"] = [delegate]\n",
    "        return tflite._original_interpreter(*args, **kwargs)\n",
    "\n",
    "    tflite.Interpreter = Interpreter_with_delegate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'birdnet_analyzer__wrapper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m WRAPPER_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/rachit/Documents/Python shit/BirdNET-Analyzer-main\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(WRAPPER_PATH)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbirdnet_analyzer__wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbirdnet\u001b[39;00m\n\u001b[1;32m      8\u001b[0m TARGET_SR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m48000\u001b[39m\n\u001b[1;32m      9\u001b[0m WINDOW_DURATION \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3.0\u001b[39m  \u001b[38;5;66;03m# seconds per prediction window\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'birdnet_analyzer__wrapper'"
     ]
    }
   ],
   "source": [
    "# -------------------- Setup Paths --------------------\n",
    "DATASET_PATH = \"/Users/rachit/Documents/Python shit/SPOT1/recordings\"\n",
    "STATIC_NOISE_PATH = \"/Users/rachit/Documents/Python shit/StaticNoise/Untitled video - Made with Clipchamp.wav\"\n",
    "WRAPPER_PATH = \"/Users/rachit/Documents/Python shit/BirdNET-Analyzer-main\"\n",
    "sys.path.append(WRAPPER_PATH)\n",
    "import birdnet_analyzer__wrapper as birdnet\n",
    "\n",
    "TARGET_SR = 48000\n",
    "WINDOW_DURATION = 30.0  # seconds per prediction window\n",
    "WINDOW_SAMPLES = int(TARGET_SR * WINDOW_DURATION)\n",
    "OUTPUT_CSV = \"classified_birdnet_per_file_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TARGET_SR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m hour, minute\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msegment_audio\u001b[39m(audio, fs\u001b[38;5;241m=\u001b[39m\u001b[43mTARGET_SR\u001b[49m, segment_duration\u001b[38;5;241m=\u001b[39mWINDOW_DURATION):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Splits audio into non-overlapping segments of WINDOW_DURATION seconds.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     segment_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(segment_duration \u001b[38;5;241m*\u001b[39m fs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TARGET_SR' is not defined"
     ]
    }
   ],
   "source": [
    "def extract_year_month_date_hour_and_minute(filename):\n",
    "    \"\"\"Extracts hour and minute from filenames like '2MM07103_20250330_143000.wav'.\"\"\"\n",
    "    match_date = re.search(r'_(\\d{8})_', filename)\n",
    "    match = re.search(r'_(\\d{6})\\.wav$', filename)\n",
    "    if match and match_date:\n",
    "        time_str = match.group(1)\n",
    "        date_str = match_date.group(1)\n",
    "        year = date_str[:4]\n",
    "        month = date_str[4:6]\n",
    "        date = date_str[6:]\n",
    "        hour = int(time_str[:2])\n",
    "        minute = int(time_str[2:4])\n",
    "        return year, month, date, hour, minute\n",
    "    return None, None, None, None, None\n",
    "\n",
    "def segment_audio(audio, fs=TARGET_SR, segment_duration=WINDOW_DURATION):\n",
    "    \"\"\"\n",
    "    Splits audio into non-overlapping segments of WINDOW_DURATION seconds.\n",
    "    \"\"\"\n",
    "    segment_samples = int(segment_duration * fs)\n",
    "    n_segments = len(audio) // segment_samples\n",
    "    if n_segments < 1:\n",
    "        return None\n",
    "    audio = audio[:n_segments * segment_samples]\n",
    "    segments = audio.reshape((n_segments, segment_samples))\n",
    "    return segments\n",
    "\n",
    "def remove_static_noise(audio, noise_ref, sr=TARGET_SR, snr_db=18):\n",
    "    \"\"\"\n",
    "    Combines time-domain noise subtraction and spectral gating for static noise removal.\n",
    "    \n",
    "    1. Time-Domain Subtraction:\n",
    "       - If noise_ref is shorter than audio, pad it using 'wrap' mode (repeat the noise).\n",
    "       - Scale the noise_ref based on the desired SNR and subtract it from the audio.\n",
    "    \n",
    "    2. Spectral Gating:\n",
    "       - Computes the STFT of the time-domain subtracted audio.\n",
    "       - Estimates a noise threshold from the noise_refâ€™s STFT.\n",
    "       - Zeroes out frequency bins below the threshold.\n",
    "       - Reconstructs the audio using inverse STFT.\n",
    "    \"\"\"\n",
    "    # --- Time-Domain Subtraction ---\n",
    "    if len(noise_ref) > len(audio):\n",
    "        noise_ref = noise_ref[:len(audio)]\n",
    "    else:\n",
    "        noise_ref = np.pad(noise_ref, (0, len(audio) - len(noise_ref)), 'wrap')\n",
    "    \n",
    "    audio_power = np.mean(audio ** 2)\n",
    "    noise_power = np.mean(noise_ref ** 2)\n",
    "    desired_noise_power = audio_power / (10 ** (snr_db / 10))\n",
    "    noise_ref_scaled = noise_ref * np.sqrt(desired_noise_power / noise_power)\n",
    "    audio_td = audio - noise_ref_scaled\n",
    "\n",
    "    # --- Spectral Gating ---\n",
    "    stft = librosa.stft(audio_td, n_fft=2048, hop_length=512)\n",
    "    magnitude, phase = np.abs(stft), np.angle(stft)\n",
    "    noise_stft = librosa.stft(noise_ref, n_fft=2048, hop_length=512)\n",
    "    noise_mag = np.abs(noise_stft)\n",
    "    noise_threshold = np.mean(noise_mag, axis=1, keepdims=True) * 1.2\n",
    "    gated_mag = np.where(magnitude > noise_threshold, magnitude, 0)\n",
    "    cleaned_stft = gated_mag * np.exp(1j * phase)\n",
    "    audio_cleaned = librosa.istft(cleaned_stft, hop_length=512)\n",
    "    return audio_cleaned\n",
    "\n",
    "def compute_acoustic_indices(y, sr):\n",
    "    \"\"\"\n",
    "    Computes acoustic indices from the audio segment:\n",
    "      - ADI (Acoustic Diversity Index): Based on Shannon entropy over frequency bins.\n",
    "      - ACI (Acoustic Complexity Index): Based on spectral flux.\n",
    "      - AEI (Acoustic Evenness Index): 1 - (normalized entropy).\n",
    "      - NDSI (Normalized Difference Soundscape Index): Ratio between bio and anthropogenic energy.\n",
    "    \"\"\"\n",
    "    f, t, Sxx = spectrogram(y, fs=sr, nperseg=1024, noverlap=512)\n",
    "    Sxx = Sxx + 1e-8  # Avoid log(0)\n",
    "    S_norm = Sxx / np.sum(Sxx, axis=0, keepdims=True)\n",
    "    ADI = np.mean(entropy(S_norm, axis=0))\n",
    "    AEI = 1.0 - (ADI / np.log(Sxx.shape[0]))\n",
    "    delta = np.abs(np.diff(Sxx, axis=1))\n",
    "    ACI_vals = np.sum(delta, axis=1) / (np.sum(Sxx[:, :-1], axis=1) + 1e-8)\n",
    "    ACI_total = np.mean(ACI_vals)\n",
    "    bio = np.logical_and(f >= 2000, f <= 11000)\n",
    "    anthro = np.logical_and(f >= 100, f <= 2000)\n",
    "    B = np.sum(Sxx[bio])\n",
    "    A = np.sum(Sxx[anthro])\n",
    "    NDSI = (B - A) / (B + A + 1e-8)\n",
    "    return ADI, ACI_total, AEI, NDSI\n",
    "\n",
    "def classify_audio_file(filepath, model, noise_clip):\n",
    "    \"\"\"\n",
    "    Loads the audio file, applies combined noise removal, segments it into 3-second windows,\n",
    "    gets BirdNET predictions, and computes acoustic indices per segment.\n",
    "    Returns a list of dictionaries (one per segment).\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(filepath, sr=TARGET_SR)\n",
    "    audio_denoised = remove_static_noise(audio, noise_clip)\n",
    "    segments = segment_audio(audio_denoised)\n",
    "    if segments is None:\n",
    "        return []\n",
    "    \n",
    "    predictions = []\n",
    "    for i, segment in enumerate(segments):\n",
    "        try:\n",
    "            segment_input = segment.reshape(1, -1)\n",
    "            df = model.predict(segment_input, samplerate=TARGET_SR, strict=True)\n",
    "            scores = df.iloc[0].values\n",
    "            if np.any(scores < 0):\n",
    "                scores = softmax(scores)\n",
    "                df.iloc[0] = scores\n",
    "            top_idx = np.argmax(df.values)\n",
    "            species = df.columns[top_idx]\n",
    "            confidence = df.values[0][top_idx]\n",
    "            ADI, ACI, AEI, NDSI = compute_acoustic_indices(segment.flatten(), sr)\n",
    "            predictions.append({\n",
    "                'Bird Species': species,\n",
    "                'Confidence': confidence,\n",
    "                'Segment': i,\n",
    "                'ADI': ADI,\n",
    "                'ACI': ACI,\n",
    "                'AEI': AEI,\n",
    "                'NDSI': NDSI\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction failed for {filepath} segment {i}:\", e)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Main Execution --------------------\n",
    "DATASET_SUBFOLDER = \"/kaggle/input/rupa12/2\"\n",
    "\n",
    "all_results = []\n",
    "model = birdnet.Model(class_output=True)\n",
    "# Pre-load the static noise clip.\n",
    "noise_clip, _ = librosa.load(STATIC_NOISE_PATH, sr=TARGET_SR)\n",
    "\n",
    "for filename in sorted(os.listdir(DATASET_SUBFOLDER)):\n",
    "    if filename.lower().endswith(\".wav\"):\n",
    "        year, month, date, hour, minute = extract_hour_and_minute(filename)\n",
    "        filepath = os.path.join(DATASET_SUBFOLDER, filename)\n",
    "        print(f\"Processing {filename} (Hour: {hour}, Minute: {minute}) ...\")\n",
    "        preds = classify_audio_file(filepath, model, noise_clip)\n",
    "        for pred in preds:\n",
    "            all_results.append({\n",
    "                \"Filename\": filename,\n",
    "                \"Year\": year,\n",
    "                \"Month\": month,\n",
    "                \"Date\": date,\n",
    "                \"Hour\": hour,\n",
    "                \"Minute\": minute,\n",
    "                \"Second\": (pred[\"Segment\"]+1)*WINDOW_DURATION\n",
    "                \"Segment\": pred[\"Segment\"],\n",
    "                \"Bird Species\": pred[\"Bird Species\"],\n",
    "                \"Confidence\": pred[\"Confidence\"],\n",
    "                \"ADI\": pred[\"ADI\"],\n",
    "                \"ACI\": pred[\"ACI\"],\n",
    "                \"AEI\": pred[\"AEI\"],\n",
    "                \"NDSI\": pred[\"NDSI\"]\n",
    "            })\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"Classification results saved to\", OUTPUT_CSV)\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Boxplot Visualization --------------------\n",
    "# Create boxplots for each index (Confidence, ADI, ACI, AEI, NDSI) by Hour.\n",
    "for idx in [\"Confidence\", \"ADI\", \"ACI\", \"AEI\", \"NDSI\"]:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    results_df.boxplot(column=idx, by=\"Hour\", grid=True)\n",
    "    plt.title(f\"{idx} per Hour (Boxplot)\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"Hour\")\n",
    "    plt.ylabel(idx)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"boxplot_{idx.lower()}_per_hour.png\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
